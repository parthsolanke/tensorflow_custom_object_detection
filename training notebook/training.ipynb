{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UTI-IrDwFa5"
      },
      "outputs": [],
      "source": [
        "# mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vUvWt4xw1Lk"
      },
      "outputs": [],
      "source": [
        "# installing tensorflow-gpu\n",
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XglJPUfKDKaz"
      },
      "outputs": [],
      "source": [
        "# general imports\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import io\n",
        "import xml.etree.ElementTree as ET\n",
        "import argparse\n",
        "import cv2\n",
        "import csv\n",
        "from PIL import Image\n",
        "from collections import namedtuple\n",
        "\n",
        "# checking availability of GPU\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")\n",
        "\n",
        "#checking tensorflow version\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRBDvs07xIkh"
      },
      "outputs": [],
      "source": [
        "# cloning tensorflow models repository\n",
        "%cd /content/drive/MyDrive/tensorflow_custom_object_detection\n",
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz_p72y0xTzY"
      },
      "outputs": [],
      "source": [
        "# compiling protobuf\n",
        "%cd /content/drive/MyDrive/tensorflow_custom_object_detection/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMaV50fbytDZ"
      },
      "outputs": [],
      "source": [
        "# installing COCO API\n",
        "!git clone https://github.com/cocodataset/cocoapi.git\n",
        "%cd cocoapi/PythonAPI\n",
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMoF86aD0HSl"
      },
      "outputs": [],
      "source": [
        "# installing object detection API\n",
        "%cp -r pycocotools /content/drive/MyDrive/tensorflow_custom_object_detection/models/research\n",
        "%cd ..\n",
        "%cd ..\n",
        "%cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1SxCONI0rTy"
      },
      "outputs": [],
      "source": [
        "# testing model builder\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xyzg3K0-cMY"
      },
      "outputs": [],
      "source": [
        "# getting data\n",
        "%cd /content/drive/MyDrive/tensorflow_custom_object_detection\n",
        "\n",
        "!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n",
        "!unzip -q WeaponS.zip\n",
        "\n",
        "!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS_bbox.zip\n",
        "!unzip -q WeaponS_bbox.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fesaUzxU9OdE"
      },
      "outputs": [],
      "source": [
        "# storing data into a directory\n",
        "!mkdir data\n",
        "\n",
        "# creating folders for test and train data\n",
        "!mkdir data/images data/train_labels data/test_labels\n",
        "\n",
        "# combining images and annotations\n",
        "!mv WeaponS/* data/images\n",
        "!mv WeaponS_bbox/* data/train_labels\n",
        "\n",
        "# removing zip files\n",
        "!rm -rf WeaponS_bbox.zip  WeaponS.zip WeaponS/  WeaponS_bbox/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFrZMCzR-gMf"
      },
      "outputs": [],
      "source": [
        "# sorting and adding data to test and train folders\n",
        "!ls data/train_labels/* | sort -R | head -600 | xargs -I{} mv {} data/test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDDs0Cn5--2F"
      },
      "outputs": [],
      "source": [
        "# converting all files from xml to csv and generating label_map.pbtxt\n",
        "\n",
        "%cd /content/drive/MyDrive/tensorflow_custom_object_detection/data\n",
        "\n",
        "# images extension\n",
        "images_extension = 'jpg'\n",
        "\n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text + '.' + images_extension,\n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "# Creating the `label_map.pbtxt` file\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "#creats a pbtxt file the has the class names.\n",
        "for i, class_name in enumerate(classes):\n",
        "    # display_name is optional.\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: 'Gun'\\n }}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n",
        "\n",
        "#checking the pbtxt file\n",
        "print(\"label_map.pbtxt: \")\n",
        "!cat label_map.pbtxt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AzK9VqztHKk"
      },
      "outputs": [],
      "source": [
        "#checks if the images box position is placed within the image.\n",
        "\n",
        "%cd /content/drive/MyDrive/tensorflow_custom_object_detection/data\n",
        "# path to images\n",
        "images_path = 'images'\n",
        "\n",
        "# returns the image name where an error is found \n",
        "# return the incorrect attributes; xmin, ymin, xmax, ymax.\n",
        "for CSV_FILE in ['train_labels.csv', 'test_labels.csv']:\n",
        "  with open(CSV_FILE, 'r') as fid:  \n",
        "      print('[*] Checking file:', CSV_FILE) \n",
        "      file = csv.reader(fid, delimiter=',')\n",
        "      first = True \n",
        "      cnt = 0\n",
        "      error_cnt = 0\n",
        "      error = False\n",
        "      for row in file:\n",
        "          if error == True:\n",
        "              error_cnt += 1\n",
        "              error = False         \n",
        "          if first == True:\n",
        "              first = False\n",
        "              continue     \n",
        "          cnt += 1      \n",
        "          name, width, height, xmin, ymin, xmax, ymax = row[0], int(row[1]), int(row[2]), int(row[4]), int(row[5]), int(row[6]), int(row[7])     \n",
        "          path = os.path.join(images_path, name)\n",
        "          img = cv2.imread(path)         \n",
        "          if type(img) == type(None):\n",
        "              error = True\n",
        "              print('Could not read image', img)\n",
        "              continue     \n",
        "          org_height, org_width = img.shape[:2]     \n",
        "          if org_width != width:\n",
        "              error = True\n",
        "              print('Width mismatch for image: ', name, width, '!=', org_width)     \n",
        "          if org_height != height:\n",
        "              error = True\n",
        "              print('Height mismatch for image: ', name, height, '!=', org_height) \n",
        "          if xmin > org_width:\n",
        "              error = True\n",
        "              print('XMIN > org_width for file', name)  \n",
        "          if xmax > org_width:\n",
        "              error = True\n",
        "              print('XMAX > org_width for file', name)\n",
        "          if ymin > org_height:\n",
        "              error = True\n",
        "              print('YMIN > org_height for file', name)\n",
        "          if ymax > org_height:\n",
        "              error = True\n",
        "              print('YMAX > org_height for file', name)\n",
        "          if error == True:\n",
        "              print('Error for file: %s' % name)\n",
        "              print()\n",
        "      print()\n",
        "      print('Checked %d files and realized %d errors' % (cnt, error_cnt))\n",
        "      print(\"-----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruwVAxpPuSrt"
      },
      "outputs": [],
      "source": [
        "#removing the image \n",
        "!rm images/'armas (2815).jpg'\n",
        "\n",
        "#removing the entry for it in the csv for that image as well\n",
        "\n",
        "#reading the training csv\n",
        "df = pd.read_csv('/content/drive/MyDrive/tensorflow_custom_object_detection/data/train_labels.csv')\n",
        "# removing armas (2815).jpg\n",
        "df = df[df['filename'] != 'armas (2815).jpg']\n",
        "#reseting the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "#saving the df\n",
        "df.to_csv('/content/drive/MyDrive/tensorflow_custom_object_detection/data/train_labels.csv')\n",
        "\n",
        "#reading the testing csv\n",
        "df = pd.read_csv('/content/drive/MyDrive/tensorflow_custom_object_detection/data/test_labels.csv')\n",
        "# removing armas (2815).jpg\n",
        "df = df[df['filename'] != 'armas (2815).jpg']\n",
        "#reseting the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "#saving the df\n",
        "df.to_csv('/content/drive/MyDrive/tensorflow_custom_object_detection/data/test_labels.csv')\n",
        "\n",
        "# freeing memory\n",
        "df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faSgvhdQwB3K"
      },
      "outputs": [],
      "source": [
        "# generating tfrecords\n",
        "from object_detection.utils import dataset_util\n",
        "\n",
        "%cd /content/drive/MyDrive/tensorflow_custom_object_detection/data\n",
        "\n",
        "DATA_BASE_PATH = '/content/drive/MyDrive/tensorflow_custom_object_detection/data/'\n",
        "image_dir = DATA_BASE_PATH +'images/'\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "\t\tif row_label == 'pistol':\n",
        "\t\t\t\treturn 1\n",
        "\t\telse:\n",
        "\t\t\t\tNone\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "\t\tdata = namedtuple('data', ['filename', 'object'])\n",
        "\t\tgb = df.groupby(group)\n",
        "\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "\t\t\t\tencoded_jpg = fid.read()\n",
        "\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "\t\timage = Image.open(encoded_jpg_io)\n",
        "\t\twidth, height = image.size\n",
        "\n",
        "\t\tfilename = group.filename.encode('utf8')\n",
        "\t\timage_format = b'jpg'\n",
        "\t\txmins = []\n",
        "\t\txmaxs = []\n",
        "\t\tymins = []\n",
        "\t\tymaxs = []\n",
        "\t\tclasses_text = []\n",
        "\t\tclasses = []\n",
        "\n",
        "\t\tfor index, row in group.object.iterrows():\n",
        "\t\t\t\txmins.append(row['xmin'] / width)\n",
        "\t\t\t\txmaxs.append(row['xmax'] / width)\n",
        "\t\t\t\tymins.append(row['ymin'] / height)\n",
        "\t\t\t\tymaxs.append(row['ymax'] / height)\n",
        "\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n",
        "\t\t\t\tclasses.append(class_text_to_int(row['class']))\n",
        "\n",
        "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t\t\t\t'image/height': dataset_util.int64_feature(height),\n",
        "\t\t\t\t'image/width': dataset_util.int64_feature(width),\n",
        "\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n",
        "\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n",
        "\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
        "\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "\t\t}))\n",
        "\t\treturn tf_example\n",
        "\n",
        "for csv in ['train_labels', 'test_labels']:\n",
        "  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n",
        "  path = os.path.join(image_dir)\n",
        "  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "      tf_example = create_tf_example(group, path)\n",
        "      writer.write(tf_example.SerializeToString())\n",
        "    \n",
        "  writer.close()\n",
        "  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n",
        "  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es3ENzf9xYQg"
      },
      "outputs": [],
      "source": [
        "# getting pre-trained model as base model for transfer learning\n",
        "%cd /content/drive/MyDrive/tensorflow_custom_object_detection\n",
        "# we would be using SSD_Mobilnet_V2_320x320 pretrained model\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
        "!mkdir pretrained_model\n",
        "!tar -xvf ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz -C /content/drive/MyDrive/tensorflow_custom_object_detection/pretrained_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyQd0gjgE-ao"
      },
      "outputs": [],
      "source": [
        "# training the model\n",
        "!python model_main_tf2.py --model_dir=/content/drive/MyDrive/tensorflow_custom_object_detection/my-model \\\n",
        "--pipeline_config_path=/content/drive/MyDrive/tensorflow_custom_object_detection/my-model/pipeline.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8weLMp4K3yT"
      },
      "outputs": [],
      "source": [
        "# results after training\n",
        "\n",
        "# I0503 13:01:30.477312 140112458757952 model_lib_v2.py:708] {'Loss/classification_loss': 0.09248921,\n",
        "#  'Loss/localization_loss': 0.035992417,\n",
        "#  'Loss/regularization_loss': 0.09361376,\n",
        "#  'Loss/total_loss': 0.22209539,\n",
        "#  'learning_rate': 0.0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5kKRrQoR4HQ"
      },
      "outputs": [],
      "source": [
        "# exporting trained model\n",
        "!python exporter_main_v2.py --input_type image_tensor \\\n",
        "--pipeline_config_path /content/drive/MyDrive/tensorflow_custom_object_detection/my-model/pipeline.config \\\n",
        "--trained_checkpoint_dir /content/drive/MyDrive/tensorflow_custom_object_detection/my-model \\\n",
        "--output_directory /content/drive/MyDrive/tensorflow_custom_object_detection/exported-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w95JcgS6U4cK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/drive/MyDrive/tensorflow_custom_object_detection/exported-model'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/drive/MyDrive/tensorflow_custom_object_detection/data/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.50)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL =PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgvg4EC_eWtg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = '/content/drive/MyDrive/tensorflow_custom_object_detection/data/test3.jpg'\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2_imshow(image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
